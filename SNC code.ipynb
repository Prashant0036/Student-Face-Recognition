{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "729ba421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a6cb73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d975da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.CascadeClassifier 000002574919E590>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load face and eye cascade first\n",
    "face_cascade=cv2.CascadeClassifier(\"./model/haarcascades/haarcascade_frontalface_default.xml\")\n",
    "eye_cascade = cv2.CascadeClassifier('./model/haarcascades/haarcascade_eye.xml')\n",
    "eye_cascade\n",
    "face_cascade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ef6e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to return croped image of face with 2 or more eyes\n",
    "def get_cropped_image_if_2_eyes(image_path):\n",
    "    try:\n",
    "        img = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = img[y:y+h, x:x+w]\n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "            if len(eyes) >= 2:\n",
    "                return roi_color\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "916d2d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_of_data = \"./model/dataset/rawData/\"\n",
    "path_to_cr_data = \"./model/dataset/cropped/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ab5518b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aditya Sharma',\n",
       " 'Akansha Shishodia',\n",
       " 'Anant Jain',\n",
       " 'Deepak Singhal',\n",
       " 'Divyanka Mishra',\n",
       " 'Nishant Rohilla',\n",
       " 'Prashant Saraswat',\n",
       " 'Prerna Sharma',\n",
       " 'Ritik Kamboj',\n",
       " 'Ritika Tiwari',\n",
       " 'Sakshi',\n",
       " 'Shubham',\n",
       " 'Vansh Saini']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stu_folder_list=os.listdir(path_of_data)\n",
    "stu_folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11106ecb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: './model/dataset/cropped/Aditya Sharma cropped'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sName \u001b[38;5;129;01min\u001b[39;00m stu_folder_list:\n\u001b[0;32m      4\u001b[0m     stu_file_names_dict[sName]\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m----> 5\u001b[0m     NewDir\u001b[38;5;241m=\u001b[39m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_cr_data\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43msName\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m cropped\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sNamePhoto \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(path_of_data\u001b[38;5;241m+\u001b[39msName):\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: './model/dataset/cropped/Aditya Sharma cropped'"
     ]
    }
   ],
   "source": [
    "# To extract facial data from raw data \n",
    "stu_file_names_dict = {}\n",
    "for sName in stu_folder_list:\n",
    "    stu_file_names_dict[sName]=[]\n",
    "    NewDir=os.mkdir(path_to_cr_data+sName+\" cropped\")\n",
    "    count=1\n",
    "    for sNamePhoto in os.listdir(path_of_data+sName):\n",
    "        sNamePhotoPath=path_of_data+sName+\"/\"+sNamePhoto\n",
    "       # print(sNamePhotoPath)\n",
    "        Ret_Img_Color=get_cropped_image_if_2_eyes(sNamePhotoPath)\n",
    "        if Ret_Img_Color is not None :\n",
    "           # print(sNamePhotoPath)\n",
    "            Ret_Img_Path=(path_to_cr_data+sName+\" cropped\")+\"/\"+sName+str(count)+\".png\"\n",
    "            cv2.imwrite(Ret_Img_Path,Ret_Img_Color)\n",
    "            stu_file_names_dict[sName].append(Ret_Img_Path)\n",
    "            \n",
    "            count+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22be5139",
   "metadata": {},
   "outputs": [],
   "source": [
    "stu_file_names_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4427bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt #for wavelet function\n",
    "def w2d(img, mode='haar', level=1):\n",
    "    imArray = img\n",
    "      #print(imArray.shape)\n",
    "    #Datatype conversions\n",
    "    #convert to grayscale\n",
    "    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
    "    #convert to float\n",
    "    imArray =  np.float32(imArray)   \n",
    "    #print(imArray)\n",
    "    \n",
    "    imArray /= 255;\n",
    "   # print(imArray)\n",
    "    # compute coefficients \n",
    "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
    "   # print(coeffs)\n",
    "    #Process Coefficients\n",
    "    coeffs_H=list(coeffs)  \n",
    "   # print(coeffs_H)\n",
    "    coeffs_H[0] *= 0;  \n",
    "    print(coeffs_H)\n",
    "\n",
    "    # reconstruction\n",
    "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
    "    imArray_H *= 255;\n",
    "    imArray_H =  np.uint8(imArray_H)\n",
    "\n",
    "    return imArray_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee8b2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {}\n",
    "count = 0\n",
    "for stu_name in stu_file_names_dict.keys():\n",
    "    class_dict[stu_name] = count\n",
    "    count = count + 1\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd18d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=[],[]\n",
    "for stu_name, training_files in stu_file_names_dict.items():\n",
    "    for training_image in training_files:\n",
    "        img = cv2.imread(training_image)\n",
    "        scalled_raw_img = cv2.resize(img, (200, 200))\n",
    "        img_har = w2d(img,'db1',5)\n",
    "        scalled_img_har = cv2.resize(img_har, (200, 200))\n",
    "        #plt.imshow(img_har,cmap='gray')\n",
    "        combined_img = np.vstack((scalled_raw_img.reshape(200*200*3,1),scalled_img_har.reshape(200*200,1)))\n",
    "        X.append(combined_img)\n",
    "        y.append(class_dict[stu_name]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2aecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58705a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d615ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(len(X),160000).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093bf288",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f61363",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#test\n",
    "path_tst_img=path_of_data+stu_folder_list[0]+\"/\"+os.listdir(path_of_data+stu_folder_list[0])[0]\n",
    "print(os.listdir(path_of_data+stu_folder_list[0])[0])\n",
    "print(path_tst_img)\n",
    "#Test=cv2.imread(path_tst_img)\n",
    "#plt.imshow(Test)\n",
    "#ret_img=get_cropped_image_if_2_eyes(path_tst_img)\n",
    "img = cv2.imread(path_tst_img)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(gray,cmap='gray')\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "(x,y,w,h)=faces[0]\n",
    "print(x,y,w,h)\n",
    "roi_gray = gray[y:y+h, x:x+w]\n",
    "plt.imshow(roi_gray)\n",
    "roi_color = img[y:y+h, x:x+w]\n",
    " #           eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "  #          if len(eyes) >= 2:\n",
    "   #             return roi_color\n",
    "#plt.imshow(ret_img)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58268467",
   "metadata": {},
   "source": [
    "# Let's train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44f330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a036f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "len(y_test),X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17008d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model=svm.SVC(C=10)\n",
    "svm_model.fit(X_train,y_train)\n",
    "svm_model.predict(X_test)==y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a605e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d67fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Test\n",
    "import cv2 \n",
    "img1 = cv2.imread(\"./model/testImg/testRt.png\")\n",
    "plt.imshow(img1)\n",
    "faces = face_cascade.detectMultiScale(img1, 1.3, 5)\n",
    "(x,y,w,h)=faces[0]\n",
    "print(x,y,w,h)\n",
    "img1 = img1[y:y+h, x:x+w]\n",
    "scalled_raw_img1 = cv2.resize(img1, (200, 200))\n",
    "img_har1 = w2d(img1,'db1',5)\n",
    "scalled_img_har1 = cv2.resize(img_har1, (200, 200))\n",
    "#plt.imshow(scalled_raw_img,cmap='gray')\n",
    "combined_img1 = np.vstack((scalled_raw_img1.reshape(200*200*3,1),scalled_img_har1.reshape(200*200,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5211f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[]\n",
    "list1.append(combined_img1)\n",
    "list1 = np.array(list1).reshape(len(list1),160000).astype(float)\n",
    "list1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce384fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=svm_model.predict(list1)\n",
    "for k,v in class_dict.items():\n",
    "    if v==result[0]:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3fbe18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f3edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(svm_model,\"saved_model_for_SNC.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f84358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"stu_class_dict.json\",\"w\") as f:\n",
    "    f.write(json.dumps(class_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c2dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
